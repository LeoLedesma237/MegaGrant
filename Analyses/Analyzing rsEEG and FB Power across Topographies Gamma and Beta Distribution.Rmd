---
title: "Analyzing resting-state EEG and Spelling Performance in Young Adults (Gamma & Beta)"
author: "Leandro Ledesma"
date: "2024-12-24"
output: html_document
---

### Universal block code settings

```{r setup}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(comment = NULL)
knitr::opts_chunk$set(warning = FALSE)

```

### Loading in packages

```{r loading in the packages, warning = FALSE}
library(tidyverse)
library(ggplot2)
library(readxl)
library(kableExtra)
library(broom) # Converts regression outputs into dataframes using the tidy() function
library(psych)
library(MASS, exclude = "select") # This package is loaded with QuantPsyc, must exclude "select" or you wont be able to use it. 
library(QuantPsyc) # Can use the lm.beta function to calculate the standardized betas
library(car) # To calculate VIF
library(performance) # ICC 
library(lme4) #glmer
library(interactions) # interact_plot
library(emmeans)
library(effects) #plot(allEffects(model))
library(sjPlot) # plot_model
library(MuMIn)
```

### Loading in our data and doing some data cleaning

*Update- I commented out the fft data since it is not relevant*

```{r load in the predictors covariates and outcome data, warning= FALSE}
# Set the working directory
Mega <- '\\\\files.times.uh.edu/labs/MIR_Lab/MEGAGRANT/STUDY 1/FINAL_DS'
setwd(Mega)

# load data
demo <- read_excel("Demo/MegaGrant_TBL_Database_Newest_MCh with duration.xlsx")
ARFA <- read.csv("ARFA/ARFA.Spelling.Errors.Scored.csv")
CFIT <- read.csv("CFIT/CFIT.scores.csv")
#fftx <- read.csv("EEG/rsEEG/topographyFBAvgPowFFT.csv")
welchx <-  read.csv("EEG/rsEEG/topographyFBAvgPowWelch.csv")
eeg_qs <- read_excel("EEG/rsEEG/Wet_EEG_Cleaning_Final_Report.xlsx")
eeg_mismatch <- read_excel("EEG/rsEEG/MegaGrant_TBL.xlsx")
Medical <- read_excel("Medical_History/TBL_WHOQOL_BRIEF_Medical_S1_S3_DM_06.xlsx",  sheet = "med s1")

# Data cleaning (Renaming variables and selectings vars of interest)
CFIT <- select(CFIT, ID, IQRS = Raw.Scores)
ARFA <- select(ARFA, ID, TSE = Total_SpellingError, TSE_theta = theta)
demo <- demo %>%
  select(S1 = `S1 reg-list`,
         ID, 
         Sex, 
         Age, 
         Group) %>%
  mutate(ID = as.numeric(ID),
         Age = as.numeric(Age)) 
eeg_qs <- select(eeg_qs, File_Name, Start_Recording_Sec, Percent_Remaining, EEG_Rank2, Interpolated_Chan_Num )
eeg_mismatch <- select(eeg_mismatch, ID, RAW)
Medical2 <- select(Medical, ID, HeadTrauma, Health2epilepsy, Health2autism, ADD, Dislexia)


# EEG data cleaning
welchx$ID <- as.numeric(gsub("\\D", "",  sapply(str_split(welchx$filename,"_"), function(x) x[1])))
welchx$Condition <- ifelse(grepl("Close", welchx$filename),"Closed","Open")
welchx <- select(welchx, -filename)
names(welchx) <- c(paste0(names(welchx)[1:(length(welchx)-2)],"_welchx"),"ID", "Condition")


# EEG QS cleaning
eeg_qs$Condition <- ifelse(grepl("Close", eeg_qs$File_Name),"Closed","Open")
eeg_qs$ID <- as.numeric(gsub("\\D", "", sapply(str_split(eeg_qs$File_Name,"_"), function(x) x[1])))
eeg_qs <- select(eeg_qs, -File_Name)
eeg_mismatch$ID <- as.numeric(eeg_mismatch$ID)
eeg_mismatch$RAW <- as.numeric(eeg_mismatch$RAW)

### Combine the dataset into one
data <- demo %>%
  full_join(CFIT, by = "ID") %>%
  full_join(ARFA, by = "ID") %>%
  full_join(Medical2, by = "ID") %>%
  full_join(eeg_mismatch, by = "ID") %>%
  full_join(eeg_qs, by = "ID") %>%
  #full_join(fftx, by =  c("ID","Condition")) %>%
  full_join(welchx, by =  c("ID","Condition"))

# Drop any NA's from the following variables
data <- drop_na(data, ID)
data <- drop_na(data, Condition)


# Keep only unique instances
data <- unique(data)

# Any duplicates? (no duplicates)
dup <- data %>%
  group_by(ID) %>%
  summarise(duplicates = n())

cat("There are:",sum(dup$duplicates>2),"duplicates in the data")

# Keep subjects only from study 1
data <- data %>%
  filter(S1 == "+")
```


### Addressing Issue with rsEEG file names

- Some RAW files have mismatching names with IDs.
- On closer inspection there seems to be no issues after all. 

```{r addressing rsEEG name issue}
# Select ID and RAW
datt <- select(data, ID, RAW)

# Identify which files are mismatched
datt <- datt %>%
  mutate(mismatch = ifelse(ID != RAW, "Mismatch", "-"))

```


### Convert data into fully long format

- This is to make plotting easier later on
```{r convert data into fully long format}
# Convert data to long
dataL <- data %>%
  pivot_longer(c(frontal_absdelta_welchx:occipital_relbeta_welchx), names_to = "Topo_PowType_FB", values_to = "Power")

# Introduce variables to disaggregate the data better
dataL <- dataL %>%
  mutate(
    # Create a variable for topography
    Topography = case_when(
      grepl("frontal", Topo_PowType_FB) ~ "Frontal",
      grepl("temporal", Topo_PowType_FB) ~ "Temporal",
      grepl("parietal", Topo_PowType_FB) ~ "Parietal",
      grepl("occipital", Topo_PowType_FB) ~ "Occipital"),
    
    # Create a variable for power type
    Power_Type = case_when(
      grepl("abs", Topo_PowType_FB) ~ "Absolute",
      grepl("avg", Topo_PowType_FB) ~ "Average",
      grepl("rel", Topo_PowType_FB) ~ "Relative"),
    
    # Create a variable for Frequency Band
    Frequency_Band = case_when(
      grepl("delta", Topo_PowType_FB) ~ "Delta",
      grepl("theta", Topo_PowType_FB) ~ "Theta",
      grepl("alpha", Topo_PowType_FB) ~ "Alpha",
      grepl("beta", Topo_PowType_FB) ~ "Beta",
    )
  )

# Drop the unnecessary variable with all three vars combined
dataL <- select(dataL, - Topo_PowType_FB)

# Convert some variables to factor for easier data viewing
dataL$Topography <- factor(dataL$Topography)
dataL$Power_Type <- factor(dataL$Power_Type)
dataL$Frequency_Band <- factor(dataL$Frequency_Band)

```



### Remove subjects that do not meet criteria

- No self-report injury
- No Epilepsy
- No ADD
- Extremely poor spellers (more than 3 SD below the mean)
- Too old compared to average (more than 3 Sd from the mean)
- **Note**: Calculating z-scores must be done before removing any IDs from the dataset and must be done within conditions!

*Update- modification occurred, we will now keep dyslexics and ppl with low performance on the CFIT in the data*


```{r keep non rejects subjects}
# Slice the dataset so there is one row per subject
sliced_data <- dataL %>%
  select(S1:Dislexia) %>%
  group_by(ID) %>%
  slice_head(n=1) %>%
  ungroup()

# Scale some variables to later remove extremes
sliced_data$IQRSz <- scale(sliced_data$IQRS)
sliced_data$TSEz <- scale(sliced_data$TSE)
sliced_data$Agez <- scale(sliced_data$Age)

# Create categorical variations of the variables above
sliced_data$Too_bad_spll <- ifelse(sliced_data$TSEz >=3 , "Y", "N")
sliced_data$Too_old <- ifelse(sliced_data$Agez >=3 , "Y", "N")

# Create an exclusion criteria for the behavioral data (Before accounting for noisy EEG data)
sliced_data <- sliced_data %>%
  mutate(Exclusion = case_when(
    HeadTrauma == "Y" | 
    Health2epilepsy == "Y" | 
    Health2autism == "Y" |
    ADD == "Y" |
    Too_bad_spll == "Y" |
    Too_old == "Y" ~ "Y",
    TRUE ~ "N"
  ))


# Indicate our starting sample size
cat("We are starting out with",length(unique(sliced_data$ID)),"unique ids that have at least one eyes open/closed rsEEG recording\n")

# Express how many subjects are being removed for injury, epilepsy, or autism
cat("We are removing",sum(sliced_data$Exclusion == "Y", na.rm = T),"participants for having head trauma, epilepsy, autism, ADD, extremly poor spellers (3SD +), or older than 3SD from the mean\n")

# Create a table specifically for excluded subjects to clean and then report numbers
Excluded <- sliced_data %>% filter(Exclusion == "Y") %>% select(HeadTrauma:Dislexia, Too_bad_spll, Too_old ) # We included dislexia here to report the numbers
Included <- sliced_data %>% filter(Exclusion != "Y") 
  
# Clean the table a bit (convert NAs into N)
Excluded[is.na(Excluded)] <- "N"

# Quickly look at the frequency of responses for this dataset
sapply(Excluded, function(x) table(x))

# Report the number of unique IDs we have left
cat("This leaves us with data from",nrow(Included),"participants with at least one rsEEG recording\n")

# Create a dataset that contains only participants that were not excluded
data2L <- dataL %>%
  filter(ID %in% Included$ID)

# Everything checks out
setdiff(Included$ID, data2L$ID)
setdiff(data2L$ID, Included$ID)
```

### Early Demographics

The demographics before we removed bad EEG recordings
- The sample size for Age is one less than it should be because of an NA

```{r initial demographics info}
# slice the data again
sliced_data_demo <- data2L %>%
  group_by(ID) %>%
  slice_head(n=1) %>%
  ungroup()

describe(sliced_data_demo$Age)
round(prop.table(table(sliced_data_demo$Sex)),2)
table(sliced_data_demo$Group)

```



### Removing Subjects with bad EEG data

We will remove EEG data that:
- has more than 30% of data missing due to segmentation rejection
- has 7 or more channels that were interpolated
- has a rank lower than 70% of 61 (max rank in an EEG recording)


```{r keep subjects with good EEG data}
# Slice the dataset for both eyes open and eyes closed
sliced_EO <- data2L %>%
  filter(Condition == "Open") %>%
  select(ID,Start_Recording_Sec:Condition) %>%
  group_by(ID) %>%
  slice_head(n=1) %>%
  ungroup()

sliced_EC <- data2L %>%
  filter(Condition == "Closed") %>%
  select(ID,Percent_Remaining:Condition) %>%
  group_by(ID) %>%
  slice_head(n=1) %>%
  ungroup()

# Create categorical exclusion variables
sliced_EO$Not_Engh_EEG <- ifelse(sliced_EO$Percent_Remaining < 80, "Y", "N")
sliced_EO$Low_Rank <- ifelse(sliced_EO$EEG_Rank2 < .7 * max(sliced_EO$EEG_Rank2), "Y", "N" )
sliced_EO$Many_Chan_Intp <-  ifelse(sliced_EO$Interpolated_Chan_Num >= 7, "Y", "N")

sliced_EC$Not_Engh_EEG <- ifelse(sliced_EC$Percent_Remaining < 80, "Y", "N")
sliced_EC$Low_Rank <- ifelse(sliced_EC$EEG_Rank2 < .7 * max(sliced_EC$EEG_Rank2), "Y", "N" )
sliced_EC$Many_Chan_Intp <-  ifelse(sliced_EC$Interpolated_Chan_Num >= 7, "Y", "N")

# Create an exclusion variable for them
sliced_EO <- sliced_EO %>%
  mutate(Exclusion = case_when(
    Not_Engh_EEG == "Y" |
    Low_Rank == "Y" |
    Many_Chan_Intp == "Y" ~ "Y",
    TRUE ~ "N"
  ))

sliced_EC <- sliced_EC %>%
  mutate(Exclusion = case_when(
    Not_Engh_EEG == "Y" |
    Low_Rank == "Y" |
    Many_Chan_Intp == "Y" ~ "Y",
    TRUE ~ "N"
  ))

# Create a a dataet with excluded EEG recordings
Excluded_EO <- sliced_EO %>% filter(Exclusion == "Y") %>% select(Not_Engh_EEG:Many_Chan_Intp) 
Excluded_EC <- sliced_EC %>% filter(Exclusion == "Y") %>% select(Not_Engh_EEG:Many_Chan_Intp) 

# Indicate how many total EEG recordings were not included due to bad data quality
paste0(nrow(Excluded_EO)," Eyes Open EEG recordings were not included for having less than 80% of data, having 7 or more interpolated channels, or having a rank less than 0.7 * 61 after cleaning")
paste0(nrow(Excluded_EC)," Eyes Closed EEG recordings were not included for having less than 80% of data, having 7 or more interpolated channels, or having a rank less than 0.7 * 61 after cleaning")

# Quickly look at the frequency of responses for this dataset
sapply(Excluded_EO, function(x) table(x))
sapply(Excluded_EC, function(x) table(x))

# Create datasets with the IDs that should be included
Included_EO <- sliced_EO %>% filter(Exclusion != "Y")
Included_EC <- sliced_EC %>% filter(Exclusion != "Y")

# Create datasets that have bad EEG recordings removed
EO_L <- filter(data2L, ID %in%  Included_EO$ID)
EC_L <- filter(data2L, ID %in% Included_EC$ID)

# Introduce a scaled age score
EO_L$Age_c <- c(scale(EO_L$Age, center = T, scale = F))
EC_L$Age_c <- c(scale(EC_L$Age, center = T, scale = F))

# Report the final sample sizes for eyes open and eyes closed EEG data
paste0(nrow(Included_EO), " subjects had good enough data for eyes open")
paste0(nrow(Included_EC), " subjects had good enough data for eyes closed")

```

### Final Demographic for our final datasets

```{r final demographics}
# Slice the data one last time for EO and EC
sliced_EO_demo <- EO_L %>%
  group_by(ID) %>%
  slice_head(n=1) %>%
  ungroup()

sliced_EC_demo <- EC_L %>%
  group_by(ID) %>%
  slice_head(n=1) %>%
  ungroup()

# Describe the descriptives for the final datasets
describe(sliced_EO_demo$Age)
round(prop.table(table(sliced_EO_demo$Sex)),2)
table(sliced_EO_demo$Group)


describe(sliced_EC_demo$Age)
round(prop.table(table(sliced_EC_demo$Sex)),2)
table(sliced_EC_demo$Group)

# Let's just make a decent figure showing the age distribution
sliced_EC_demo %>%
  ggplot(aes(x = Age)) +
  geom_histogram(bins = 17, fill = "white", color = "black", size = 1) +
  scale_y_continuous(expand = c(0, 0))

```

### Sum of Errors vs IRT Theta Values (Data Visualization)

Here we can visualize the differences between using someones score for spelling errors, which is just a sum of errors across 22 items, versus including those items into a graded response IRT model and then obtaining theta values. As we can see from the plots, both approaches to score spelling errors are positively correlated as seen with the first plot. A good advantage from the theta values is how this response is normal instead of skewed. Technically, this does not matter because this is being used as a predictor, nonetheless theta values are a much better approach than simply a raw score sum since they account for differences in the difficulty of an item. 

The violin graph is a bit misleading, the smallest value possible for spelling errors is 0. 

```{r visualizing the difference between the sum of errors vs theta values}
# Briefly plotting the differnece between total spelling error and theta values
sliced_EO_demo %>%
  ggplot(aes(x = TSE, TSE_theta)) +
  geom_point() +
  theme_classic()

# Comparing raw score sums vs theta values
sliced_EO_demo %>%
  select(TSE, TSE_theta) %>%
  stack() %>%
  rename(Scores = values, Scoring_Type = ind) %>%
  ggplot(aes(x= Scoring_Type, Scores)) +
  facet_wrap(~Scoring_Type, scale = "free") +
  geom_violin(trim=FALSE, size = 1) +
  geom_boxplot(size = 1) +
  theme_classic()

# Fleshed out descriptives
describe(sliced_EO_demo$TSE)
describe(sliced_EO_demo$TSE_theta)
```


### Generating the Final Datasets

Six datasets will be generated, these are combinations of conditions (eyes open vs eyes closed) and power type (absolute, mean, relative). The reasoning for this is there no strong justification to keep this information in one dataset and then control for it by including these factors as fixed effects. This would overcomplicates the model and require more interaction terms to make sense of things, which is confusing. 


```{r generatin the final datasets}
# Changing variables to factors
EO_L <- EO_L %>% 
  mutate(Topography = factor(Topography, levels = c("Frontal", "Temporal", "Parietal", "Occipital")),
         Frequency_Band = factor(Frequency_Band, levels = c("Delta", "Theta", "Alpha", "Beta")))
EC_L <- EC_L %>% 
  mutate(Topography = factor(Topography, levels = c("Frontal", "Temporal", "Parietal", "Occipital")),
         Frequency_Band = factor(Frequency_Band, levels = c("Delta", "Theta", "Alpha", "Beta")))

# Create a list to generate the 6 plots that we are interested in. 
data_list <- list(
  EO_ABS = filter(EO_L, Power_Type == "Absolute", Condition == "Open"),
  EO_AVG = filter(EO_L, Power_Type == "Average", Condition == "Open"),
  EO_REL = filter(EO_L, Power_Type == "Relative", Condition == "Open"),
  EC_ABS = filter(EO_L, Power_Type == "Absolute", Condition == "Closed"),
  EC_AVG = filter(EO_L, Power_Type == "Average", Condition == "Closed"),
  EC_REL = filter(EO_L, Power_Type == "Relative", Condition == "Closed")
)

```



### EEG Skewness Visualization 

Here we want to plot the distribution of the outcome for all EEG related covariates (factors). The goal is to visualize the distribution of the data, identifying if there is skewness and then inform the model that we will use later on, aka using regular mixed models or generalized mixed models. 

We will be combining absolute, mean, and relative power into a single dataset to easily compare distribution across power types. 


```{r EEG data skewness visulization }
# Load in package
library(patchwork)
library(ggh4x) # facet_grid2

# Aesthetics (Leo version)
theme_clean <- function() {
  theme_minimal() +
    theme(legend.position = "bottom",
          panel.grid.minor = element_blank(),
          plot.title = element_text(hjust = 0.5))
}

# Plot the general distribution of power (outcome)
rbind(
  data_list$EO_ABS, 
  data_list$EO_AVG,
  data_list$EO_REL
) %>%
  ggplot(aes(x= Power)) +
  geom_histogram()+
  facet_wrap(~Power_Type, scales = "free") +
  theme_classic() +
  labs(title = "General distribution of Power for Absolute, Mean, and Relative") +
  theme_clean()


# Plot disaggregated Eyes Open Power Distribution for Absolute, Mean, Relative
EO_ABS_plot <- data_list$EO_ABS %>%
  ggplot(aes(x = Power, fill = Frequency_Band)) +
  geom_histogram(color = "black") +
  facet_grid2(Frequency_Band ~ Topography, scales = "free", independent = "all") +
  labs(title = "Eyes Open: Absolute Power") +
  theme_clean()

EO_AVG_plot <- data_list$EO_AVG %>%
  ggplot(aes(x = Power, fill = Frequency_Band)) +
  geom_histogram(color = "black") +
  facet_grid2(Frequency_Band ~ Topography, scales = "free", independent = "all") +
  labs(title = "Eyes Open: Mean Power", y = NULL) +
  theme_clean()

EO_REL_plot <- data_list$EO_REL %>%
  ggplot(aes(x = Power, fill = Frequency_Band)) +
  geom_histogram(color = "black") +
  facet_grid2(Frequency_Band ~ Topography, scales = "free", independent = "all") +
  labs(title = "Eyes Open: Relative Power", y = NULL) +
  theme_clean()

# Generate the plots
EO_ABS_plot + EO_AVG_plot + EO_REL_plot


# Plot disaggregated Eyes Closed Power Distribution for Absolute, Mean, Relative
EC_ABS_plot <- data_list$EC_ABS %>%
  ggplot(aes(x = Power, fill = Frequency_Band)) +
  geom_histogram(color = "black") +
  facet_grid2(Frequency_Band ~ Topography, scales = "free", independent = "all") +
  labs(title = "Eyes Closed: Absolute Power") +
  theme_clean()

EC_AVG_plot <- data_list$EC_AVG %>%
  ggplot(aes(x = Power, fill = Frequency_Band)) +
  geom_histogram(color = "black") +
  facet_grid2(Frequency_Band ~ Topography, scales = "free", independent = "all") +
  labs(title = "Eyes Closed: Mean Power", y = NULL) +
  theme_clean()

EC_REL_plot <- data_list$EC_REL %>%
  ggplot(aes(x = Power, fill = Frequency_Band)) +
  geom_histogram(color = "black") +
  facet_grid2(Frequency_Band ~ Topography, scales = "free", independent = "all") +
  labs(title = "Eyes Closed: Relative Power", y = NULL) +
  theme_clean()

# Generate the plots
EC_ABS_plot + EC_AVG_plot + EC_REL_plot
```



### Data Visualization (Indepth)

We want to look at the relationship between spelling errors and EEG power after controlling for several covariates which include:
- Age (15-33)
- Frequency Band (Delta, Theta, Alpha, Beta)
- Topography (Frontal, Temporal, Parietal, Occipital)

This will be done 6 times- for the combinations of 2 conditions (eyes open, eyes closed) and 3 power types (absolute, mean power, relative). 

```{r Plotting the data for fun delete me later}
# Create a for loop to generate the plots
plot_list <- list()

for(ii in 1:length(data_list)){ 

  # Extract current dataset
  current_dat <- data_list[[ii]]
  current_condition <- unique(current_dat$Condition)
  current_power_type <- unique(current_dat$Power_Type)
    
  # Group by spelling performance (three levels)
  current_dat <- current_dat %>%
    mutate(
      TSE_theta_cat = case_when(
      TSE_theta < -1 ~ "Poor Spellers",
      TSE_theta <=  1 ~ "Average Spellers",
      TRUE ~ "Good Spellers"),
      TSE_theta_cat = factor(TSE_theta_cat, levels = c("Poor Spellers", "Average Spellers", "Good Spellers")))
  
  # Generate a plot for this
  plot_list[[ii]] <- current_dat %>%
    ggplot(aes(x = Age, y = Power)) +
    facet_grid2(Topography ~ Frequency_Band, scales = "free", independent = "all") +
    geom_smooth(aes(group = TSE_theta_cat, color = TSE_theta_cat), se = FALSE, size = 1.5, alpha = .5) +
    geom_smooth(aes(group = "All Subjects", color = "All Subjects"), se = FALSE, size = 1, alpha = .5) +
    scale_color_manual(values = c("#000000", "#B3B3B3", "#FF0000", "blue"),
                       labels = c(levels(current_dat$TSE_theta_cat), "All Subjects")) +
    labs(title = paste0(current_power_type, " Power for Spelling Performance by Topography and Frequency Band\n(Eyes ", current_condition, ")"), 
         color = "Group") +
    theme_classic()
}

# Show the plots on the Console
plot_list


```



### Running parallel processing

Unsure if this actually is improving the computational speed of the model. I also don't feel like testing it. 

```{r running parallel processing}
library(future)
plan(multisession, workers = 12)  # Set number of workers (check your specs); use 'multisession' for windows or 'multicore' for Mac/Linux

```


## Research Question
- We are interested in investigating spelling performance/spelling error as a predictor of EEG activity. We hypothesize that spelling ability will result in differences in brain activity while controlling for covariates like Age, Group (Bio vs Ins), and topography. However, this is more exploratory since literature on this topic is mixed and I don't believe anyone has done this type of analysis on adults. Thus we will also include interactions to see if the relationship between spelling performance and EEG activity (average FB power) is moderated by other variables like age, or topography. 


### Identify that gamma models can capture the distribution of absolute and mean power

```{r identifying that gamma models can capture the spread of our power outcome}
# Run an empty gamma mixed model
m_gam_test <- glmer(Power ~ 1 + (1|ID), 
                     data = data_list$EO_ABS, 
                     family = Gamma(link = "log"))

# Calculate the shape and scale parameters
shape_scale_fun <- function(model) {
  # This will only work on gamma mixed models with a log link function
  b0 <- fixef(model)[["(Intercept)"]]
  mu <- exp(b0)
  phi <- sigma(model)^2 # Residual sd
  var_int <- as.data.frame(VarCorr(model))$vcov[as.data.frame(VarCorr(model))$grp == "ID"] # Random intercepts
  variance <- mu^2 * (phi + var_int)
  
  # Calculate the gamma parameters
  shape <- mu^2/variance
  scale <- variance/mu
  return(list(shape = shape, scale = scale))
}

# Calculate the shape and scale from the model
shape <- shape_scale_fun(m_gam_test)$shape
scale <- shape_scale_fun(m_gam_test)$scale

# Overlap the gamma distribution over the response variable
ggplot(data_list$EO_ABS, aes(x = Power)) +
  geom_histogram(aes(y=..density..), alpha = 0.5) +
  geom_function(fun = dgamma, args = list(shape = shape, scale = scale),
                aes(color = "yes"), 
                linewidth = 1) +
  labs(title = "Fitted Gamma Distribution for Eyes Open Absolute Power") +
  theme_clean()
```


### Idenfitying that beta models can capture the distribution of relatice power

```{r identifying that beta models can capture the spread of our power outcome}
# Checking disaggregation of the proportions
xtabs(Power~ Topography + Frequency_Band, filter( data_list$EO_REL, ID == "10027")) %>%
  addmargins() %>%
  round(2)

# Load in the package to run a multivariate beta regression
library(glmmTMB)

# Run an empty beta mixed model
m_bet_test <- glmmTMB(Power ~ 1 + (1|ID), 
                      data = data_list$EO_REL, 
                      dispformula = ~ 1, 
                      family = beta_family(link = "logit"), #
                      ziformula = ~0) 

# Calculate the shape1 and shape2 parameters
shape1_shape2_fun <- function(model) {
  # This will only work on beta mixed models with a logit link function
  b0 <- fixef(model)$cond[["(Intercept)"]]
  mu <- 1 / (1 + exp(-b0)) # Same as plogis()
  phi <- sigma(model) # Phi 
  
  # Calculate the beta parameters
  shape1 <- mu * phi
  shape2 <- (1 - mu) * phi
  return(list(shape1 = shape1, shape2 = shape2))
}

# Calculate the shape1 and shape2 from the model 
shape1 <- shape1_shape2_fun(m_bet_test)$shape1
shape2 <- shape1_shape2_fun(m_bet_test)$shape2

# Overlap the beta distribution over the response variable
ggplot(data_list$EO_REL, aes(x = Power)) +
  geom_histogram(aes(y=..density..), alpha = 0.5) +
  geom_function(fun = dbeta, args = list(shape1 = shape1, shape2 = shape2),
                aes(color = "yes"), 
                linewidth = 1) +
  labs(title = "Fitted Beta Distribution for Eyes Open Relative Power") +
  theme_clean()


# Let's see what happens if we add the predictor for frequency band for both mu and phi
m_bet_test2 <- update(m_bet_test, . ~ . - 1 + Frequency_Band,
                      dispformula = ~  - 1 + Frequency_Band,
                      REML = TRUE)

#m_bet_test2 <- update(m_bet_test, . ~ . - 1 + Frequency_Band) # Keeping phi constant

# Create a shape1 and shape2 function
shape1_shape2_fun2 <- function(model) {
  # This function only works for beta mixed models with a logit link function and phi log link
  # Extract fixed effects for the mean model (conditional)
  estimates <- fixef(model)$cond
  mu <- sapply(estimates, function(x) plogis(x))
  
  # Extract the fixed effects for the phi model
  phi_estimates <- fixef(model)$disp
  phi <- sapply(phi_estimates, function(x) exp(x))  
  
  # Calculate shape1 and shape2
  shape1 = mu*phi
  shape2 = (1-mu) * phi
  return(list(shape1 = shape1, shape2 = shape2))

}

# Extract the shape1 and shape2 parameters
shape1_vec <- shape1_shape2_fun2(m_bet_test2)$shape1
shape2_vec <- shape1_shape2_fun2(m_bet_test2)$shape2

# Cheese to generate the plots cause having them in one is difficult
beta_plots <- list()
unique_fb <- c("Delta","Theta","Alpha","Beta")

for(ii in 1:4) {
beta_plots[[ii]] <- filter(data_list$EO_REL, Frequency_Band == unique_fb[ii]) %>%
  ggplot(aes(x = Power)) +
  geom_histogram(aes(y=..density..), alpha = 0.5) +
  geom_function(fun = dbeta, args = list(shape1 = shape1_vec[ii], shape2 = shape2_vec[ii]),
                aes(color = NULL), 
                linewidth = 1) +
  scale_y_continuous(limits = c(0, 12)) +
  scale_x_continuous(limits = c(0, .8)) +
  labs(title = paste0("Beta Distribution for ",unique_fb[ii]," Eyes Open\nRelative Power" )) +
  
  theme_clean()
}

# Plot all the graphs
main_plot <- (beta_plots[[1]] + beta_plots[[2]])/(beta_plots[[3]] + beta_plots[[4]])
main_plot

# Comparing beta models
logLik(m_bet_test); logLik(m_bet_test2)
AIC(m_bet_test); BIC(m_bet_test2)
lrtest(m_bet_test, m_bet_test2)

```





### Model 1: EEG Absolute Power Analysis (Eyes Open)

Effect Size of the best model:
- 35% of the variance is explained by the fixed effects only
- 54% of the variance is explained by the full model
- 19% of the variance is explained by the random effects only

```{r EEG absolute power analysis eyes open}
# Run the model
abs_EO_mod1 <- glmer(Power ~ Frequency_Band + Topography + Sex + Age_c + TSE_theta + (1|ID), 
                     data = data_list$EO_ABS, 
                     family = Gamma(link = "log"),
                     control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1500000)))

abs_EO_mod2 <- update(abs_EO_mod1, . ~ . + Frequency_Band:Topography) # introduces one two-way interaction
abs_EO_mod3 <- update(abs_EO_mod2, . ~ . + TSE_theta:Age_c + TSE_theta:Frequency_Band) # introduces two two-way inteactions
abs_EO_mod4 <- update(abs_EO_mod3, . ~ . + TSE_theta*Age_c*Frequency_Band) # Introduces a three way interaction plus another two way interaction

# Update the random effects (It does absolutely nothing!)
abs_EO_mod5 <- update(abs_EO_mod4, . ~ . + (1|Frequency_Band:Topography))

# model comparison (Model 4 is the best model)
anova(abs_EO_mod1, abs_EO_mod2, abs_EO_mod3, abs_EO_mod4, abs_EO_mod5)

# Omnibust Test for Model 4
Anova(abs_EO_mod4, type = "III")

# Report the effect sizes (interpret delta only)
r.squaredGLMM(abs_EO_mod4)
```

### Model 2: EEG Absolute Power Analysis (Eyes Closed)


Effect Size of the best model:
- 54% of the variance is explained by the fixed effects only
- 69% of the variance is explained by the full model
- 15% of the variance is explained by the random effects only

```{r EEG absolute power analysis eyes closed}
# Run the model
abs_EC_mod1 <- glmer(Power ~ Frequency_Band + Topography + Sex + Age_c + TSE_theta + (1|ID), 
                     data = data_list$EC_ABS, 
                     family = Gamma(link = "log"),
                     control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1500000)))

abs_EC_mod2 <- update(abs_EC_mod1, . ~ . + Frequency_Band:Topography) # introduces one two-way interaction
abs_EC_mod3 <- update(abs_EC_mod2, . ~ . + TSE_theta:Age_c + TSE_theta:Frequency_Band) # introduces two two-way inteactions
abs_EC_mod4 <- update(abs_EC_mod3, . ~ . + TSE_theta*Age_c*Frequency_Band) # Introduces a three way interaction plus another two way interaction

# Update the random effects (It does absolutely nothing!)
abs_EC_mod5 <- update(abs_EC_mod4, . ~ . + (1|Frequency_Band:Topography))

# model comparison (Model 4 is the best model)
anova(abs_EC_mod1, abs_EC_mod2, abs_EC_mod3, abs_EC_mod4, abs_EC_mod5)

# Omnibust Test for Model 4
Anova(abs_EC_mod4, type = "III")

# Report the effect sizes (interpret delta only)
r.squaredGLMM(abs_EC_mod4)
```

### Model 3: EEG Mean Power Analysis (Eyes Open)


Effect Size of the best model:
- 68% of the variance is explained by the fixed effects only
- 78% of the variance is explained by the full model
- 10% of the variance is explained by the random effects only

```{r EEG mean power analysis eyes open}
# Run the model
avg_EO_mod1 <- glmer(Power ~ Frequency_Band + Topography + Sex + Age_c + TSE_theta + (1|ID), 
                     data = data_list$EO_AVG, 
                     family = Gamma(link = "log"),
                     control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1500000)))

avg_EO_mod2 <- update(avg_EO_mod1, . ~ . + Frequency_Band:Topography) # introduces one two-way interaction
avg_EO_mod3 <- update(avg_EO_mod2, . ~ . + TSE_theta:Age_c + TSE_theta:Frequency_Band) # introduces two two-way inteactions
avg_EO_mod4 <- update(avg_EO_mod3, . ~ . + TSE_theta*Age_c*Frequency_Band) # Introduces a three way interaction plus another two way interaction

# Update the random effects (It does absolutely nothing!)
avg_EO_mod5 <- update(avg_EO_mod4, . ~ . + (1|Frequency_Band:Topography))

# model comparison (Model 4 is the best model)
anova(avg_EO_mod1, avg_EO_mod2, avg_EO_mod3, avg_EO_mod4, avg_EO_mod5)

# Omnibust Test for Model 4
Anova(avg_EO_mod4, type = "III")

# Report the effect sizes (interpret delta only)
r.squaredGLMM(avg_EO_mod4)
```

### Model 4: EEG Mean Power Analysis (Eyes Closed)


Effect Size of the best model:
- 73% of the variance is explained by the fixed effects only
- 82% of the variance is explained by the full model
- 9% of the variance is explained by the random effects only

```{r EEG mean power analysis eyes closed}
# Run the model
avg_EC_mod1 <- glmer(Power ~ Frequency_Band + Topography + Sex + Age_c + TSE_theta + (1|ID), 
                     data = data_list$EC_AVG, 
                     family = Gamma(link = "log"),
                     control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1500000)))

avg_EC_mod2 <- update(avg_EC_mod1, . ~ . + Frequency_Band:Topography) # introduces one two-way interaction
avg_EC_mod3 <- update(avg_EC_mod2, . ~ . + TSE_theta:Age_c + TSE_theta:Frequency_Band) # introduces two two-way inteactions
avg_EC_mod4 <- update(avg_EC_mod3, . ~ . + TSE_theta*Age_c*Frequency_Band) # Introduces a three way interaction plus another two way interaction

# Update the random effects (It does absolutely nothing!)
avg_EC_mod5 <- update(avg_EC_mod4, . ~ . + (1|Frequency_Band:Topography))

# model comparison (Model 4 is the best model)
anova(avg_EC_mod1, avg_EC_mod2, avg_EC_mod3, avg_EC_mod4, avg_EC_mod5)

# Omnibust Test for Model 4
Anova(avg_EC_mod4, type = "III")

# Report the effect sizes (interpret delta only)
r.squaredGLMM(avg_EC_mod4)
```

### Model 5: EEG Relative Power Analysis (Eyes Open)


Effect Size of the best model:
- 43% of the variance is explained by the fixed effects only
- 43% of the variance is explained by the full model
- 0% of the variance is explained by the random effects only

```{r EEG relative power analysis eyes open}
# Run the model
rel_EO_mod1 <- glmer(Power ~ Frequency_Band + Topography + Sex + Age_c + TSE_theta + (1|ID), 
                     data = data_list$EO_REL, 
                     family = Gamma(link = "log"),
                     control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1500000)))

rel_EO_mod2 <- update(rel_EO_mod1, . ~ . + Frequency_Band:Topography) # introduces one two-way interaction
rel_EO_mod3 <- update(rel_EO_mod2, . ~ . + TSE_theta:Age_c + TSE_theta:Frequency_Band) # introduces two two-way inteactions
rel_EO_mod4 <- update(rel_EO_mod3, . ~ . + TSE_theta*Age_c*Frequency_Band) # Introduces a three way interaction plus another two way interaction

# Update the random effects (It does absolutely nothing!)
rel_EO_mod5 <- update(rel_EO_mod4, . ~ . + (1|Frequency_Band:Topography))

# model comparison (Model 4 is the best model)
anova(rel_EO_mod1, rel_EO_mod2, rel_EO_mod3, rel_EO_mod4, rel_EO_mod5)

# Omnibust Test for Model 4
Anova(rel_EO_mod4, type = "III")

# Report the effect sizes (interpret delta only)
r.squaredGLMM(rel_EO_mod4)
```


### Model 6: EEG Relative Power Analysis (Eyes Closed)


Effect Size of the best model:
- 59% of the variance is explained by the fixed effects only
- 61% of the variance is explained by the full model
- 2% of the variance is explained by the random effects only

```{r EEG relative power analysis eyes open}
# Run the model
rel_EC_mod1 <- glmer(Power ~ Frequency_Band + Topography + Sex + Age_c + TSE_theta + (1|ID), 
                     data = data_list$EC_REL, 
                     family = Gamma(link = "log"),
                     control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1500000)))

rel_EC_mod2 <- update(rel_EC_mod1, . ~ . + Frequency_Band:Topography) # introduces one two-way interaction
rel_EC_mod3 <- update(rel_EC_mod2, . ~ . + TSE_theta:Age_c + TSE_theta:Frequency_Band) # introduces two two-way inteactions
rel_EC_mod4 <- update(rel_EC_mod3, . ~ . + TSE_theta*Age_c*Frequency_Band) # Introduces a three way interaction plus another two way interaction

# Update the random effects (It does absolutely nothing!)
rel_EC_mod5 <- update(rel_EC_mod4, . ~ . + (1|Frequency_Band:Topography))

# model comparison (Model 4 is the best model)
anova(rel_EC_mod1, rel_EC_mod2, rel_EC_mod3, rel_EC_mod4, rel_EC_mod5)

# Omnibust Test for Model 4
Anova(rel_EC_mod4, type = "III")

# Report the effect sizes (interpret delta only)
r.squaredGLMM(rel_EC_mod4)
```

# Follow Up Tests (Simple Slopes)


```{r follow up tests for the significant interaction effects}
# Using emmeans to follow this up
best_mods <- list(abs_EO_mod4, 
                  abs_EC_mod4, 
                  avg_EO_mod4, 
                  avg_EC_mod4, 
                  rel_EO_mod4, 
                  rel_EC_mod4)

# Create an empty list
follow_up_list <- list()

for(ii in 1:6) {
  trends <- emtrends(best_mods[[ii]], ~ Frequency_Band | Age_c, var = "TSE_theta", at = list(Age_c = c(-1, 0, 1)))
  follow_up_list[[ii]] <- summary(trends, infer = c(TRUE, TRUE))  # Include confidence intervals and p-values
}

# Print out the follow up tests
follow_up_list
```


# Visualizing the Predicted Values


```{r visualizing the predicted values of the model}
# Ages of our data
mean_age = round(mean(data_list$EC_REL$Age, na.rm = T))
sd_age= round(sd(data_list$EC_REL$Age, na.rm = T))

# Create a list to save the plotted data
follow_up_plotted_list <- list()

# Generate a vector of names for the plots
plot_names <- c("(Absolute Power Eyes Open)",
                "(Absolute Power Eyes Closed)",
                "(Mean Power Eyes Open)",
                "(Mean Power Eyes Open)",
                "(Relative Power Eyes Open)",
                "(Relative Power Eyes Open)")

for(ii in 1:6) {
# Create it into a dataframe
plot_data <- follow_up_list[[ii]] %>%
  tibble() %>%
  rename(TSE_Slope = TSE_theta.trend) %>%
  mutate(Age_c = factor(Age_c, 
                       levels = c(-1, 0, 1),
                       labels = c(mean_age - sd_age, mean_age, mean_age + sd_age)),
         Frequency_Band = factor(Frequency_Band, levels = c("Delta", "Theta", "Alpha", "Beta")),
         Significant = ifelse(p.value < .05, "Yes", "No"),
         Significant = factor(Significant, levels = c("Yes", "No")))

# Set a distance for fat apart geoms should be
geom_distance = .45

# Create a graph
follow_up_plotted_list[[ii]] <- plot_data %>%
  ggplot(aes(x = Frequency_Band, y = TSE_Slope, color = Significant)) +
  geom_point(size = 3.5, position = position_dodge(geom_distance)) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), width = 0.2,
                position = position_dodge(geom_distance),
                size = 1) +
  facet_wrap(~Age_c) +
  geom_hline(yintercept = 0) +
  labs(title = paste0("Slope of Spelling Errors and EEG Power Across Frequency Bands by Age\n", plot_names),
       x = "Age",
       y = "Slope",
       color = "Significant") +
  scale_color_manual(values = c("Yes" = "skyblue", "No" = "lightcoral")) +
  theme_classic()

}

follow_up_plotted_list


```



